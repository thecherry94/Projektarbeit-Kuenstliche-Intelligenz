{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c741b716",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "This notebook extracts the following features from images and saves them in a csv file:\n",
    "* aspect ratio\n",
    "* adkögöadjhg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78befe3",
   "metadata": {},
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cdc04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-written modules\n",
    "import modules.feature_extraction as fe\n",
    "\n",
    "# external libraries\n",
    "import os, pandas, cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64306ccf",
   "metadata": {},
   "source": [
    "## Set Variables That Are Often Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b4f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relImgPath = os.path.join(\"data\", \"images\", \"original\")\n",
    "csvPath = os.path.join(\"data\",\"features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5548b51",
   "metadata": {},
   "source": [
    "## Select the Images, Class Names and Class Indices to Be Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69830fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names and indices: {'bottleOpener': 0, 'canOpener': 1, 'corcScrew': 2, 'multiTool': 3}\n"
     ]
    }
   ],
   "source": [
    "imgPaths = []\n",
    "for dirpath, dirnames, filenames in os.walk(relImgPath):\n",
    "    if dirnames:\n",
    "        classes = {}\n",
    "        for index, name in enumerate(dirnames):\n",
    "            classes[name]=index\n",
    "    for filename in filenames:# [f for f in filenames if f.endswith(suportedImgFomats)]:\n",
    "        imgPaths.append(os.path.join(dirpath, filename))\n",
    "\n",
    "# TODO delete SPLITIT folder\n",
    "print(\"Class names and indices:\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df026cb4",
   "metadata": {},
   "source": [
    "## Extract the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dee5cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 %\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mappend(row, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m imgName \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprepared\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanny\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanny closed gaps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     24\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontours\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax area contour\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mharris\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshi-tomasi\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 25\u001b[0m         \u001b[43mfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimgName\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mformat\u001b[39m((\u001b[38;5;241m100.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(imgPaths))\u001b[38;5;241m*\u001b[39mi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation on the feature dataframe:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Dokumente\\GitHub\\ai-assignment\\modules\\feature_extraction.py:282\u001b[0m, in \u001b[0;36mdisplay_image\u001b[1;34m(img, title, destroy)\u001b[0m\n\u001b[0;32m    280\u001b[0m cv2\u001b[38;5;241m.\u001b[39mresizeWindow(title, \u001b[38;5;28mmin\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1536\u001b[39m), \u001b[38;5;28mmin\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m864\u001b[39m))\n\u001b[0;32m    281\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(title, img)\n\u001b[1;32m--> 282\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m destroy:\n\u001b[0;32m    284\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO add all extracted features\n",
    "features = [\"Relative Image Path\",\n",
    "           \"Class Name\",\n",
    "           \"Class Index\",\n",
    "           \"Aspect Ratio\",\n",
    "           \"Number of Corners (Harris)\",\n",
    "           \"Number of Corners (Shi-Tomasi)\",\n",
    "           \"Perimeter Area Ratio\"]\n",
    "\n",
    "df = pandas.DataFrame(columns=features)\n",
    "\n",
    "for i, path in enumerate(imgPaths):\n",
    "    c = path.split(os.sep)[-2]\n",
    "    img = fe.prepared_image(path)\n",
    "    ratio = fe.aspect_ratio(img)#path) \n",
    "    numCornersH = fe.num_corners(img, detector=\"harris\")#fe.harris_corner_detection(img)#,path)#path)\n",
    "    numCornersST = fe.num_corners(img, detector=\"shi-tomasi\")#fe.shi_tomasi_corner_detection(img)#path)\n",
    "    ratioPerim = fe.perimeter_area_ratio(img)\n",
    "    \n",
    "    row = pandas.Series([path, c, classes[c], ratio, numCornersH, numCornersST, ratioPerim], index = features)\n",
    "    df = df.append(row, ignore_index=True)\n",
    "    \n",
    "    for imgName in [\"original\", \"prepared\", \"canny\", \"canny closed gaps\", \n",
    "                    \"contours\", \"max area contour\", \"harris\", \"shi-tomasi\"]:\n",
    "        fe.display_image(fe.images[imgName], title=imgName)\n",
    "    \n",
    "    print(str(format((100./len(imgPaths))*i, \".2f\"))+\" %\", end=\"\\r\")\n",
    "\n",
    "\n",
    "print(\"Information on the feature dataframe:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec14ced",
   "metadata": {},
   "source": [
    "## Save Data as CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e06c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csvPath,';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc449c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt \n",
    "# import feature_extraction as fe\n",
    "# import cv2\n",
    "\n",
    "# img = cv2.imread(r\"D:\\Dokumente\\GitHub\\ai-assignment\\data\\images\\original\\bottleOpener\\IMG_20211220_193510786.jpg\")\n",
    "# img = cv2.resize(img, (960, 540))\n",
    "# fe.display_image(img, title=\"original image\", destroy=False)\n",
    "\n",
    "# imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# imgGray = cv2.normalize(imgGray,  imgGray, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# # hist = cv2.calcHist([imgGray], [0], None, [256], [0, 256])\n",
    "# # plt.plot(hist)\n",
    "\n",
    "# fe.display_image(imgGray, title=\"normalized grayscale image\", destroy=False)\n",
    "\n",
    "# thres = 100\n",
    "# imgGray[imgGray>thres] = 255\n",
    "# imgGray[imgGray<=thres] = 0\n",
    "\n",
    "# # imgGray = cv2.equalizeHist(imgGray)\n",
    "# fe.display_image(imgGray, title=\"enhanced image\")#, destroy=False)\n",
    "\n",
    "# imgTranfs = cv2.dilate(imgGray, np.ones((9,9), np.uint8))\n",
    "# # fe.display_image(imgTranfs, title=\"dilated image\", destroy=False)\n",
    "\n",
    "# imgTranfs = cv2.medianBlur(imgTranfs, 21)\n",
    "# # fe.display_image(imgTranfs, title=\"blurred image\", destroy=False)\n",
    "\n",
    "# imgGray = imgGray - cv2.absdiff(imgGray, imgTranfs)\n",
    "# imgGray = cv2.normalize(imgGray,  imgGray, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# fe.display_image(imgGray, title=\"shadows removed\")\n",
    "\n",
    "# import cv2\n",
    " \n",
    "# # # Read the original image\n",
    "# img = cv2.imread(r\"D:\\Dokumente\\GitHub\\ai-assignment\\data\\images\\original\\bottleOpener\\00c25ad620.jpg\")\n",
    "# # # Display original image\n",
    "# # cv2.imshow('Original', img)\n",
    "# # cv2.waitKey(0)\n",
    " \n",
    "# # # Convert to graycsale\n",
    "# # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# # # Blur the image for better edge detection\n",
    "# # img_blur = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
    " \n",
    "# # # Sobel Edge Detection\n",
    "# # sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
    "# # sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
    "# # sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection\n",
    "\n",
    "# # # Display Sobel Edge Detection Images\n",
    "# # cv2.imshow('Sobel X', sobelx)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.imshow('Sobel Y', sobely)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.imshow('Sobel X Y using Sobel() function', sobelxy)\n",
    "# # cv2.waitKey(0)\n",
    " \n",
    "# # # Canny Edge Detection\n",
    "# # edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "\n",
    "# # # Display Canny Edge Detection Image\n",
    "# # cv2.imshow('Canny Edge Detection', edges)\n",
    "# # cv2.waitKey(0)\n",
    "\n",
    "# # cv2.destroyAllWindows()\n",
    "\n",
    "# threshold = False\n",
    "\n",
    "# imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# imgGray = cv2.normalize(imgGray,  imgGray, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# cv2.imshow('Grayscale Image', imgGray)\n",
    "# cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "# imgTransf = cv2.GaussianBlur(imgGray, (3,3), 0)\n",
    "# imgTransf = cv2.Canny(imgTransf, 100, 200)#50, 100)\n",
    "# cv2.imshow('Canny Edge Detection', imgTransf)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# # dilation and erosion to close edge gaps\n",
    "# kernelDilEr = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "# imgTransf = cv2.dilate(imgTransf, kernelDilEr, iterations=1)\n",
    "# imgTransf = cv2.erode(imgTransf, kernelDilEr, iterations=1)\n",
    "\n",
    "# cv2.imshow('Transformed Image', imgTransf)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# # find contours in the edge map\n",
    "# cntrs, _ = cv2.findContours(imgTransf.copy(), cv2.RETR_EXTERNAL, \n",
    "#                              cv2.CHAIN_APPROX_SIMPLE)\n",
    "# if threshold:\n",
    "#     # only use contours with an area larger than the threshold \n",
    "#     areas = np.array([cv2.contourArea(c) for c in cntrs])\n",
    "#     cntrs = np.array(cntrs)[areas>threshold]\n",
    "\n",
    "# imgCntrs = img.copy()\n",
    "# imgCntrs = cv2.drawContours(imgCntrs, cntrs, -1, color=(0,0,255), thickness=2)\n",
    "# cv2.imshow('Contour Image', imgCntrs)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a0318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki1_venv",
   "language": "python",
   "name": "ki1_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
