{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023655b0",
   "metadata": {},
   "source": [
    "# Classification of Bottle Openers, Can Openers and Corc Screws by Means of AI Methods\n",
    "\n",
    "This assignment aims to provide multiple methods for classifying bottle openers, can openers and corc screws from images. The results of the different methods are to be analyzed and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2df237",
   "metadata": {},
   "source": [
    "## 1. Data Aquisition and Augmentation\n",
    "\n",
    "To train the methods for classification from images, first some training data has to be acquired. Many images have been provided in the course. They have been sorted to get only the images suitable for training. Additionally xxxxxxx images have been taken.\n",
    "\n",
    "Data augmentation is useful to get more data. The following kinds of augmentation are applied:\n",
    "* asödkfj\n",
    "* öaskdjf\n",
    "\n",
    "They are perfomed multiple times with different parameters. The results are xxxxxx images total in comparison to xxxxx original images before the augmentation. The images are saved as numpy arrays in .npy files. RELATIVE DIRECTORY???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0f983",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction\n",
    "\n",
    "The following features have been extracted from the original image dataset (without the augmented images).\n",
    "* The outer contour's aspect ratio\n",
    "* Number of corners detected via Harris Corner Detection\n",
    "* Number of corners detected via Shi-Tomasi Corner Detection\n",
    "* The outer contour's perimeter-area ratio\n",
    "\n",
    "The extracted features are saved in \"/data/features.csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237f4c4",
   "metadata": {},
   "source": [
    "## 3. Apply AI Methods\n",
    "\n",
    "A total of five AI methods is to be applied. Three of them are self-implemented from scratch: Naive Bayes Classifier, Decision Tree and Random Forest. Additionally a Convolutional Neural Network (CNN) and a CNN with Transfer Learning using tensorflow and keras have been implemented as well as an additional method which has not been reviewed during the lecture: Support Vector Machines (SVM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ed02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables required by multiple methods\n",
    "# Dictionary to get data by name\n",
    "data = dict()\n",
    "\n",
    "# Dictionary to get predictions by method name\n",
    "predictions = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa49e8c",
   "metadata": {},
   "source": [
    "### 3.1 Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997fbc6",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6945fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import HelperFunctions\n",
    "import DataAugmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69502269",
   "metadata": {},
   "source": [
    "#### Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bffa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import original images and save as numpy array\n",
    "original = np.load(\"data/images/augmented/original.npy\", allow_pickle=True)\n",
    "\n",
    "X_original = []\n",
    "y_original = []\n",
    "\n",
    "for idx, d in enumerate(original):\n",
    "    X_original.extend(d)\n",
    "    for e in d:\n",
    "        y_original.append([idx])\n",
    "        \n",
    "data[\"Original Images\"] = np.array(X_original)\n",
    "data[\"Original Labels\"] = np.array(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9c0cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = data[\"Original Images\"].shape\n",
    "IMG_SIZE = image_shape[1:3]\n",
    "IMG_SHAPE = image_shape[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd625438",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpaths, classes = HelperFunctions.load_images(os.path.join(\"data\", \"images\", \"test\"))\n",
    "\n",
    "X_tests = []\n",
    "y_tests = []\n",
    "\n",
    "for path in testpaths:\n",
    "    img = cv2.imread(path, cv2.COLOR_BGR2RGB)\n",
    "    img = DataAugmentation.resizeAndPad(img, IMG_SIZE)\n",
    "    X_tests.append(img)\n",
    "    y_tests.append(classes[path.split(os.sep)[-2]])\n",
    "    \n",
    "data[\"Test Images\"] = np.array(X_tests)\n",
    "data[\"Test Labels\"] = np.array(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81fd8e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original images: (729, 32, 32, 3), original labels: (729, 1).\n",
      "Augmented images: (299619, 32, 32, 3), augmented labels: (299619, 1).\n",
      "Test images: (126, 32, 32, 3), test labels: (126,).\n"
     ]
    }
   ],
   "source": [
    "# Import augmented images and save as numpy array\n",
    "augmented = np.load(\"data/images/augmented/augmentation.npy\", allow_pickle=True)\n",
    "\n",
    "X_augmented = []\n",
    "y_augmented = []\n",
    "\n",
    "for idx, d in enumerate(augmented):\n",
    "    X_augmented.extend(d)\n",
    "    for e in d:\n",
    "        y_augmented.append([idx])\n",
    "        \n",
    "data[\"Augmented Images\"] = np.array(X_augmented)\n",
    "data[\"Augmented Labels\"] = np.array(y_augmented)\n",
    "\n",
    "# User Feedback: shapes of image arrays\n",
    "print(f\"Original images: {data['Original Images'].shape}, original labels: {data['Original Labels'].shape}.\")\n",
    "print(f\"Augmented images: {data['Augmented Images'].shape}, augmented labels: {data['Augmented Labels'].shape}.\")\n",
    "print(f\"Test images: {data['Test Images'].shape}, test labels: {data['Test Labels'].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2fb72",
   "metadata": {},
   "source": [
    "#### Import Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad53da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the features CSV file\n",
    "features = pd.read_csv(r\"D:\\Dokumente\\GitHub\\Projektarbeit-Kuenstliche-Intelligenz\\data\\features.csv\", sep=';', header=None)\n",
    "\n",
    "# Drop unnecessary data and put classification column at the end\n",
    "features = features.iloc[1:, 3:]\n",
    "features = features.reindex(columns=[4, 5, 6, 7, 3])\n",
    "\n",
    "# Remove the multitool class\n",
    "features = features.apply(pd.to_numeric, errors=\"coerce\")\n",
    "features = features[features.iloc[:, -1] < 3]\n",
    "\n",
    "X_features = features.iloc[:, :-1]\n",
    "y_features = features.iloc[:, -1]\n",
    "\n",
    "data[\"DataFrame Features\"] = X_features\n",
    "data[\"DataFrame Classes\"] = y_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc048ef",
   "metadata": {},
   "source": [
    "### 3.2 Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06810c18",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0facbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import modules.naive_bayes as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b9cab",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ec6a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"DataFrame Features\"], \n",
    "                                                    data[\"DataFrame Classes\"], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=2)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60daa6de",
   "metadata": {},
   "source": [
    "#### Predict With Self-Implemented Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3e92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test, train)\n",
    "predictions[\"Naive Bayes\"] = (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d57a48",
   "metadata": {},
   "source": [
    "#### Predict With sklearn Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bced686",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_clf = GaussianNB()\n",
    "bayes_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bayes_clf.predict(X_test)\n",
    "predictions[\"Naive Bayes sklearn\"] = (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841d9d7",
   "metadata": {},
   "source": [
    "### 3.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b86feb",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad4cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import DecisionTree as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5e631",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "248370f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"DataFrame Features\"], \n",
    "                                                    data[\"DataFrame Classes\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1).to_numpy(dtype='float32')\n",
    "test = pd.concat([X_test, y_test], axis=1).to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bc75f",
   "metadata": {},
   "source": [
    "#### Predict With Self-Implemented Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "012578f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = dt.build_tree(train, 8, 1)\n",
    "y_pred = [dt.predict(tree, row) for row in test]\n",
    "predictions[\"Decision Tree\"] = (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fc547",
   "metadata": {},
   "source": [
    "#### Predict With sklearn Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6be325",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred = tree_clf.predict(X_test)\n",
    "predictions[\"Decision Tree sklearn\"] = (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f1e92",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c88c5b",
   "metadata": {},
   "source": [
    "#### Requiered Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff39cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import DecisionTree as dt\n",
    "import RandomForest as rf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9253bf",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b38975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"DataFrame Features\"], \n",
    "                                                    data[\"DataFrame Classes\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1).to_numpy(dtype='float32')\n",
    "test = pd.concat([X_test, y_test], axis=1).to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c183d",
   "metadata": {},
   "source": [
    "#### Predict With Self-Implemented Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecdb18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30]\n",
    "min_sizes = [3 for i in range(len(max_depths))]\n",
    "forest = rf.build_forest(train, max_depths, min_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeeb5244",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [rf.predict(forest, row) for row in test]\n",
    "predictions[\"Random Forest\"] = (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579613d4",
   "metadata": {},
   "source": [
    "#### Predict With sklearn Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5808eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "predictions[\"Random Forest sklearn\"] = (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a3939",
   "metadata": {},
   "source": [
    "### 3.4 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4da0c",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eaec344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78481fa9",
   "metadata": {},
   "source": [
    "#### Predict With Previously Self-Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd9af898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "# Load previously trained model\n",
    "model = models.load_model('models/v2')\n",
    "y_pred = np.argmax(model.predict(data[\"Test Images\"]), axis=1)\n",
    "predictions[\"CNN\"] = (data[\"Test Labels\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affddb95",
   "metadata": {},
   "source": [
    "### 3.5 Transfer Learning With a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad12bd",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e9b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a507f79",
   "metadata": {},
   "source": [
    "#### Predict With Previously Adapted and Self-Trained Transfer Learning Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d745f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('models/tl_v1')\n",
    "y_pred = np.argmax(model.predict(data[\"Test Images\"]), axis=1)\n",
    "predictions[\"CNN Transfer Learning\"] = (data[\"Test Labels\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483c97b",
   "metadata": {},
   "source": [
    "## 4. Compare Some Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a21f7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import HelperFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19f6b223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "Naive Bayes: \n",
      "Accuracy:\t0.545\n",
      "Precision:\t0.4614444444444444\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.545\n",
      "F1-Score:\t0.44140889225209645\n",
      "-----------------------------------------------------------------------------\n",
      "Naive Bayes sklearn: \n",
      "Accuracy:\t0.545\n",
      "Precision:\t0.4614444444444444\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.545\n",
      "F1-Score:\t0.44140889225209645\n",
      "-----------------------------------------------------------------------------\n",
      "Decision Tree: \n",
      "Accuracy:\t0.47368421052631576\n",
      "Precision:\t0.5150636913804424\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.47368421052631576\n",
      "F1-Score:\t0.4880154053086384\n",
      "-----------------------------------------------------------------------------\n",
      "Decision Tree sklearn: \n",
      "Accuracy:\t0.44360902255639095\n",
      "Precision:\t0.5447194315118844\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.44360902255639095\n",
      "F1-Score:\t0.4751694049939664\n",
      "-----------------------------------------------------------------------------\n",
      "Random Forest: \n",
      "Accuracy:\t0.46616541353383456\n",
      "Precision:\t0.511310777304376\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.46616541353383456\n",
      "F1-Score:\t0.4840242289205879\n",
      "-----------------------------------------------------------------------------\n",
      "Random Forest sklearn: \n",
      "Accuracy:\t0.5488721804511278\n",
      "Precision:\t0.5575477154424522\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.5488721804511278\n",
      "F1-Score:\t0.5457494502411926\n",
      "-----------------------------------------------------------------------------\n",
      "CNN: \n",
      "Accuracy:\t0.9285714285714286\n",
      "Precision:\t0.9321969097716606\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.9285714285714286\n",
      "F1-Score:\t0.9288386179683049\n",
      "-----------------------------------------------------------------------------\n",
      "CNN Transfer Learning: \n",
      "Accuracy:\t0.4365079365079365\n",
      "Precision:\t0.7223885174928514\n",
      "Loss:\t\t-1\n",
      "Recall:\t\t0.4365079365079365\n",
      "F1-Score:\t0.42854327848607027\n"
     ]
    }
   ],
   "source": [
    "for method in predictions:\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(f\"{method}: \")\n",
    "    print(HelperFunctions.get_scores(predictions[method][0], predictions[method][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc17ea5",
   "metadata": {},
   "source": [
    "## 5. Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e226c7d",
   "metadata": {},
   "source": [
    "#### Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7561f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import HelperFunctions\n",
    "import modules.feature_extraction as fe\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479abf55",
   "metadata": {},
   "source": [
    "#### Load the Data Provided by the Examiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e079cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presentation images: (126, 32, 32, 3), presentation labels: (126,).\n",
      "31.75 %\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPresentation Labels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_tests)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPresentation images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPresentation Images\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, presentation labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPresentation Labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_imgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m features\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32mD:\\Dokumente\\GitHub\\Projektarbeit-Kuenstliche-Intelligenz\\modules\\feature_extraction.py:339\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(imgpaths, classes, display_imgs, imgs2show, show_all)\u001b[0m\n",
      "File \u001b[1;32mD:\\Dokumente\\GitHub\\Projektarbeit-Kuenstliche-Intelligenz\\modules\\feature_extraction.py:295\u001b[0m, in \u001b[0;36mdisplay_image\u001b[1;34m(img, title, destroy)\u001b[0m\n\u001b[0;32m    293\u001b[0m cv2\u001b[38;5;241m.\u001b[39mresizeWindow(title, \u001b[38;5;28mmin\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1536\u001b[39m), \u001b[38;5;28mmin\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m864\u001b[39m))\n\u001b[0;32m    294\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(title, img)\n\u001b[1;32m--> 295\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m destroy:\n\u001b[0;32m    298\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "testpaths, classes = HelperFunctions.load_images(os.path.join(\"data\", \"images\", \"presentation\"))\n",
    "\n",
    "X_presentation = []\n",
    "y_presentation = []\n",
    "\n",
    "for path in testpaths:\n",
    "    img = cv2.imread(path, cv2.COLOR_BGR2RGB)\n",
    "    img = DataAugmentation.resizeAndPad(img, IMG_SIZE)\n",
    "    X_presentation.append(img)\n",
    "    y_presentation.append(classes[path.split(os.sep)[-2]])\n",
    "    \n",
    "data[\"Presentation Images\"] = np.array(X_tests)\n",
    "data[\"Presentation Labels\"] = np.array(y_tests)\n",
    "\n",
    "print(f\"Presentation images: {data['Presentation Images'].shape}, presentation labels: {data['Presentation Labels'].shape}.\")\n",
    "\n",
    "features = fe.extract_features(testpaths, classes, display_imgs=True, show_all = True)\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5d458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ki1_venv",
   "language": "python",
   "name": "ki1_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
